{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20180812-Práctica.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7MHiaFd_Ez0M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Empezamos por el principio, importamos las librerías que vamos a necesitar."
      ]
    },
    {
      "metadata": {
        "id": "mNAbmgaT1Qsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e14ca0a4-10ab-420e-bc45-052dd5ad7594"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5LBV3GV0G6YM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fd278e4-9c67-4304-904b-e636393c8a62"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dropout, Dense\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FsDHHTyX1Y8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "img_model = InceptionV3(include_top=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJjxlKZtE-Kn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Descargamos las descripciones y las fotos de nuestro dataset y las descomprimimos."
      ]
    },
    {
      "metadata": {
        "id": "Q7lGbWEX1mve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "49b2c462-39f3-4d47-9bbc-60a52f2ecf7b"
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip\n",
        "!unzip -o Flickr8k_text.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-13 19:39:35--  http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip\n",
            "Resolving nlp.cs.illinois.edu (nlp.cs.illinois.edu)... 192.17.58.132\n",
            "Connecting to nlp.cs.illinois.edu (nlp.cs.illinois.edu)|192.17.58.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2340801 (2.2M) [application/zip]\n",
            "Saving to: ‘Flickr8k_text.zip.1’\n",
            "\n",
            "Flickr8k_text.zip.1 100%[===================>]   2.23M  2.36MB/s    in 0.9s    \n",
            "\n",
            "2018-08-13 19:39:36 (2.36 MB/s) - ‘Flickr8k_text.zip.1’ saved [2340801/2340801]\n",
            "\n",
            "Archive:  Flickr8k_text.zip\n",
            "  inflating: CrowdFlowerAnnotations.txt  \n",
            "  inflating: ExpertAnnotations.txt   \n",
            "  inflating: Flickr8k.lemma.token.txt  \n",
            "  inflating: __MACOSX/._Flickr8k.lemma.token.txt  \n",
            "  inflating: Flickr8k.token.txt      \n",
            "  inflating: Flickr_8k.devImages.txt  \n",
            "  inflating: Flickr_8k.testImages.txt  \n",
            "  inflating: Flickr_8k.trainImages.txt  \n",
            "  inflating: readme.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TpKta9UFHk4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\n",
        "!unzip -q Flickr8k_Dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YU3cR83Htgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1e3Tb5fFi_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Abrimos el fichero con las descripciones y las volcamos en un diccionario tratándolas previamente."
      ]
    },
    {
      "metadata": {
        "id": "q7B7eluHGsn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fname = 'Flickr8k.token.txt'\n",
        "img_to_caps = dict()\n",
        "\n",
        "with open(fname, 'r') as f:\n",
        "    for line in f:\n",
        "        tokens = line.split(' ')\n",
        "        img_fname, num = tokens[0].split('#')\n",
        "        caption = ' '.join(tokens[1:]).strip()\n",
        "        if img_fname not in img_to_caps: img_to_caps[img_fname] = []\n",
        "        img_to_caps[img_fname].append(caption)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBO_8ZenHBHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_vocab = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BWHmE6wHJha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tk = text.Tokenizer(nb_words=n_vocab)\n",
        "\n",
        "texts = []\n",
        "for img_name in img_to_caps:\n",
        "    texts += img_to_caps[img_name]\n",
        "\n",
        "tk.fit_on_texts(texts)\n",
        "sorted_word_counts = sorted(tk.word_counts.items(), key=lambda x: x[1])\n",
        "sorted_word_counts = sorted_word_counts[::-1][:n_vocab]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJRywcZTHOzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sorted_word_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRyKzfP-INQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenizamos y ordenamos las palabras."
      ]
    },
    {
      "metadata": {
        "id": "X0pONS5M9v4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0cd03a34-2daa-4750-ed00-2983c463c1a4"
      },
      "cell_type": "code",
      "source": [
        "tk = text.Tokenizer(nb_words=n_vocab)\n",
        "\n",
        "texts = []\n",
        "for img_name in img_to_caps:\n",
        "    texts += img_to_caps[img_name]\n",
        "\n",
        "tk.fit_on_texts(texts)\n",
        "sorted_word_counts = sorted(tk.word_counts.items(), key=lambda x: x[1])\n",
        "sorted_word_counts = sorted_word_counts[::-1][:n_vocab]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/text.py:172: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IiIDQxpe9-ZK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_int = {t[0]: i for i,t in enumerate(sorted_word_counts)}\n",
        "int_to_word = {i: t[0] for i,t in enumerate(sorted_word_counts)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfwgPNWF-BtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_seq_len = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1iBLkpBEIVlY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creamos las secuencias."
      ]
    },
    {
      "metadata": {
        "id": "TTKfC1Zb-GSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_to_seqs = {}\n",
        "for img_fname, captions in img_to_caps.items():\n",
        "    seqs = []\n",
        "    for caption in captions:\n",
        "        seqs.append([word_to_int[w] for w in caption.split() if w in word_to_int])\n",
        "    img_to_seqs[img_fname] = seqs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDSgLmaD-JuG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_to_padded_seqs, img_to_next_chars = {}, {}\n",
        "for img_fname, seqs in img_to_seqs.items():\n",
        "    partial_seqs = []\n",
        "    next_words = []\n",
        "    for seq in seqs:\n",
        "        for i in range(1,len(seq)):\n",
        "            partial_seqs.append(seq[:i])\n",
        "            next_words.append(seq[i])\n",
        "    padded_partial_seqs = sequence.pad_sequences(partial_seqs, max_seq_len)\n",
        "    \n",
        "    next_words_1hot = np.zeros([len(next_words), n_vocab], dtype=np.bool)\n",
        "    for i,next_word in enumerate(next_words):\n",
        "        next_words_1hot[i,next_word] = 1\n",
        "    \n",
        "    img_to_padded_seqs[img_fname] = padded_partial_seqs\n",
        "    img_to_next_chars[img_fname] = next_words_1hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHgE2T5vIafg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Empezamos con nuestro modelo. Como RNN vamos a usar GRU."
      ]
    },
    {
      "metadata": {
        "id": "RpA4BGO3-NhK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_lst, y_lst = [], []\n",
        "for img_fname in img_to_padded_seqs:\n",
        "    X_lst.append(img_to_padded_seqs[img_fname])\n",
        "    y_lst.append(img_to_next_chars[img_fname])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwniOJhK-RNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, y = np.concatenate(X_lst, axis=0), np.concatenate(y_lst, axis=0)\n",
        "X = np.expand_dims(X, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNCT2VDj-VgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(256, input_shape=(max_seq_len,1)))\n",
        "model.add(Dense(n_vocab,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDcFutGJ-Yu8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose=0,\n",
        "                                  save_best_only=True, mode='min')\n",
        "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
        "callbacks_list = [model_checkpoint, tensorboard]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvqiRkoUJU-5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Entrenamos nuestro modelo."
      ]
    },
    {
      "metadata": {
        "id": "7jJqY1kK-drF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "c76427e8-3bac-41d2-8cb2-6bf3b32e382d"
      },
      "cell_type": "code",
      "source": [
        "nb_epoch = 20\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\r   128/219751 [..............................] - ETA: 3:06 - loss: 2.9453"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "219751/219751 [==============================] - 165s 749us/step - loss: 2.8887\n",
            "Epoch 2/20\n",
            "219751/219751 [==============================] - 163s 743us/step - loss: 2.8447\n",
            "Epoch 3/20\n",
            "219751/219751 [==============================] - 158s 719us/step - loss: 2.8091\n",
            "Epoch 4/20\n",
            "219751/219751 [==============================] - 160s 728us/step - loss: 2.7774\n",
            "Epoch 5/20\n",
            "219751/219751 [==============================] - 160s 727us/step - loss: 2.7477\n",
            "Epoch 6/20\n",
            "219751/219751 [==============================] - 157s 713us/step - loss: 2.7203\n",
            "Epoch 7/20\n",
            "219751/219751 [==============================] - 157s 715us/step - loss: 2.6947\n",
            "Epoch 8/20\n",
            "219751/219751 [==============================] - 157s 717us/step - loss: 2.6718\n",
            "Epoch 9/20\n",
            "219751/219751 [==============================] - 159s 722us/step - loss: 2.6493\n",
            "Epoch 10/20\n",
            "219751/219751 [==============================] - 159s 724us/step - loss: 2.6280\n",
            "Epoch 11/20\n",
            "219751/219751 [==============================] - 160s 728us/step - loss: 2.6102\n",
            "Epoch 12/20\n",
            "219751/219751 [==============================] - 157s 713us/step - loss: 2.5912\n",
            "Epoch 13/20\n",
            "219751/219751 [==============================] - 157s 712us/step - loss: 2.5735\n",
            "Epoch 14/20\n",
            "219751/219751 [==============================] - 158s 717us/step - loss: 2.5566\n",
            "Epoch 15/20\n",
            "219751/219751 [==============================] - 157s 714us/step - loss: 2.5421\n",
            "Epoch 16/20\n",
            "219751/219751 [==============================] - 158s 718us/step - loss: 2.5266\n",
            "Epoch 17/20\n",
            "219751/219751 [==============================] - 157s 715us/step - loss: 2.5137\n",
            "Epoch 18/20\n",
            "219751/219751 [==============================] - 158s 719us/step - loss: 2.5013\n",
            "Epoch 19/20\n",
            "219751/219751 [==============================] - 158s 717us/step - loss: 2.4903\n",
            "Epoch 20/20\n",
            "219751/219751 [==============================] - 158s 718us/step - loss: 2.4804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa843970cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "77ovfXwZFdfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6b651966-35ca-4c6a-c04d-a2c4e4dc9f2b"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1101892\r\n",
            "-rw-r--r-- 1 root root    2918552 Oct 14  2013 CrowdFlowerAnnotations.txt\r\n",
            "drwxr-xr-x 3 root root       4096 Aug 13 21:16 datalab\r\n",
            "-rw-r--r-- 1 root root     346674 Oct 14  2013 ExpertAnnotations.txt\r\n",
            "drwxr-xr-x 2 root root     417792 Oct  3  2012 Flicker8k_Dataset\r\n",
            "-rw-r--r-- 1 root root 1115419746 Oct 24  2013 Flickr8k_Dataset.zip\r\n",
            "-rw-r--r-- 1 root root      25801 Oct 10  2013 Flickr_8k.devImages.txt\r\n",
            "-rw-r--r-- 1 root root    3244761 Feb 16  2012 Flickr8k.lemma.token.txt\r\n",
            "-rw-r--r-- 1 root root      25775 Oct 10  2013 Flickr_8k.testImages.txt\r\n",
            "-rw-r--r-- 1 root root    2340801 Oct 28  2013 Flickr8k_text.zip\r\n",
            "-rw-r--r-- 1 root root    3395237 Oct 14  2013 Flickr8k.token.txt\r\n",
            "-rw-r--r-- 1 root root     154678 Oct 10  2013 Flickr_8k.trainImages.txt\r\n",
            "drwxrwxr-x 3 root root       4096 Aug 14 18:47 __MACOSX\r\n",
            "-rw-r--r-- 1 root root       1821 Oct 14  2013 readme.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ruKuuqiJpZU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a cargar en nuestro modelos los pesos generados en un paso anterior. Para probarlo intentamos generar una salida aleatoria."
      ]
    },
    {
      "metadata": {
        "id": "J0NgOITW_JIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading model from weight\n",
        "\n",
        "weight_fname = 'weights.01-2.95.hdf5'\n",
        "model.load_weights(weight_fname)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gLnB_XWf_LjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "977fe706-3dcd-46ec-883e-1b7679cd321c"
      },
      "cell_type": "code",
      "source": [
        "# Generate random start\n",
        "\n",
        "num_iter = 100\n",
        "curr_seq = np.zeros([1,max_seq_len,1])\n",
        "curr_seq[0,:,0] = X[np.random.randint(X.shape[0])].reshape(1,-1)\n",
        "\n",
        "for i in curr_seq[0,:,0]:\n",
        "    if i != 0: print(sorted_word_counts[int(i)][0], end=' ')\n",
        "print()\n",
        "\n",
        "for i in range(num_iter):\n",
        "    prediction = model.predict(curr_seq)\n",
        "    idx = np.argmax(prediction)\n",
        "    next_word = sorted_word_counts[idx][0]\n",
        "    curr_seq[0,:max_seq_len-1,0] = curr_seq[0,1:,0]\n",
        "    curr_seq[0,max_seq_len-1,0] = idx\n",
        "    print(next_word, end=' ')\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog through \n",
            "through a field with a in its mouth mouth the water the beach in the background her her her her a man in a blue shirt is a ball in front of a white people and blue on the grass a man water and blue shirt on a beach in front of a white people and a blue shirt in the background her a man in a blue shirt and a blue shirt in the background her a ball in front of a white and a red shirt and a blue shirt on a beach with people in the background "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}